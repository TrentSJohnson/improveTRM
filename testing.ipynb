{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trentjohnson/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, datetime, date\n",
    "\n",
    "from graphprocessing import *\n",
    "from models.greed import Greed\n",
    "#from models.hs import RSL, TRM_RSL, RSLL\n",
    "from models.local_ratio import Local_Ratio\n",
    "from models.trm import TRM\n",
    "from models.uga import UGA_RLS\n",
    "\n",
    "\n",
    "class Testing:\n",
    "    def test_(self, algorithms, data, interval, start_time_, epsilon, radius):\n",
    "        print('started thread')\n",
    "        start_time_dt = data[start_time_][np.random.choice(data.index)]\n",
    "        td = timedelta(minutes=interval)\n",
    "        graph = build_cwgraph(data, start_time_dt, start_time_dt + td, radius=radius, epsilon=epsilon)\n",
    "        while len(graph.nodes) < 4:\n",
    "            print('failed')\n",
    "            start_time_dt = data[start_time_][np.random.choice(data.index)]\n",
    "            graph = build_cwgraph(data, start_time_dt, start_time_dt + td, radius=radius, epsilon=epsilon)\n",
    "        print('nodes:', len(graph.nodes))\n",
    "        temp = []\n",
    "        tempt = []\n",
    "        for algo in algorithms:\n",
    "            print(str(algo))\n",
    "            start = datetime.now()\n",
    "            score = algo.test(graph)[1]\n",
    "            temp.append(score)\n",
    "            tempt.append((datetime.now() - start).total_seconds())\n",
    "            print(score)\n",
    "        return (temp, tempt, len(list(graph.nodes)), start_time_dt, get_shortest_assignment(graph))\n",
    "\n",
    "    def test(self, algorithms, data, interval, start_time_='started_at', epsilon=1.0, radius=500, trials=10):\n",
    "        self.scores = []\n",
    "        # epochs = int((max(data.starttime)-start_time).total_seconds()/(60*15))\n",
    "        self.runtimes = []\n",
    "        self.graphs = []\n",
    "        self.times = []\n",
    "        results = []\n",
    "        for i in range(trials):\n",
    "            results.append(self.test_(algorithms, data, interval, start_time_, epsilon, radius))\n",
    "        scores = [results[i][0] for i in range(len(results))]\n",
    "        runtimes = [results[i][1] for i in range(len(results))]\n",
    "        graph_sizes = [results[i][2] for i in range(len(results))]\n",
    "        times = [results[i][3] for i in range(len(results))]\n",
    "        sdists = [results[i][4] for i in range(len(results))]\n",
    "        return scores, runtimes, times, graph_sizes, sdists\n",
    "\n",
    "\n",
    "def run_test(data, name='citi', interval=1):\n",
    "    testing = Testing()\n",
    "    scores, runtimes, times, graphs, sdists = testing.test([Greed(), UGA_RLS(), Local_Ratio(), TRM(), RSL(), TRM_RSL(), ],\n",
    "                                                           data, interval=interval, epsilon=0.2, trials=5)\n",
    "\n",
    "    cols = ['Greed', 'UGA_RSL', 'RSL1', 'Local_Ratio', 'TRM', 'RSL', 'TRM_RSL', ]\n",
    "    # cols=['Greed']\n",
    "    scores_df = pd.DataFrame(np.abs(scores),\n",
    "                             columns=cols)\n",
    "    runtimes_df = pd.DataFrame(np.abs(runtimes),\n",
    "                               columns=cols)\n",
    "    scores_df.to_csv('outputs/scores_' + name + '.csv')\n",
    "    runtimes_df.to_csv('outputs/runtimes_' + name + '.csv')\n",
    "    times_df = pd.DataFrame(times)\n",
    "    graphs_df = pd.DataFrame(graphs)\n",
    "    times_df.to_csv('outputs/times_' + name + '.csv')\n",
    "    graphs_df.to_csv('outputs/graphs_' + name + '.csv')\n",
    "    sdists_df = pd.DataFrame(sdists)\n",
    "    sdists_df.to_csv('outputs/sdists_'+name+'.csv')\n",
    "\n",
    "\n",
    "def metrodate(s):\n",
    "    date, time = s.split(' ')\n",
    "    month, day, year = date.split('/')\n",
    "\n",
    "    hour, minute = time.split(':')\n",
    "    return {'month': int(month), 'day': int(day), 'year': int(year), 'hour': int(hour), 'minute': int(minute)}\n",
    "\n",
    "metro = pd.read_csv('data/metro-trips-2021-q1.csv')\n",
    "metro[start_time] = metro['start_time'].apply(lambda x: datetime(**metrodate(x)))\n",
    "metro[end_time] = metro['end_time'].apply(lambda x: datetime(**metrodate(x)))\n",
    "metro[start_station_name] = metro['start_station'].apply(str)\n",
    "metro[end_station_name] = metro['end_station'].apply(str)\n",
    "metro[start_lat] = metro['start_lat']\n",
    "metro[start_lng] = metro['start_lon']\n",
    "metro[end_lng] = metro['end_lon']\n",
    "metro[end_lng] = metro['end_lon']\n",
    "\n",
    "#run_test(metro, name='metro', interval=180)\n",
    "\n",
    "# graph = build_station_graph(data,data.loc[0,start_time],data.loc[0,start_time]+timedelta(minutes=15))\n",
    "# print(graph['E 6 St & Avenue D'])\n",
    "# overflow = {node:{} for node in graph.nodes() if graph.nodes[node]['type']=='overflow'}\n",
    "# underflow = {node:{} for node in graph.nodes() if graph.nodes[node]['type']=='underflow'}\n",
    "# print('edgesss',graph.edges)\n",
    "# print('vertixxx',graph.nodes)\n",
    "#\n",
    "\n",
    "# cgraph = cloned_station_vertices(graph)\n",
    "\n",
    "data = pd.read_csv('data/202105-citibike-tripdata.csv')\n",
    "data = data.loc[[type(i) == str for i in data[start_station_name]]]\n",
    "data = data.loc[[type(i) == str for i in data[end_station_name]]]\n",
    "# data = data.loc[data.index[:10000]]\n",
    "data[start_time] = data[start_time].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "data[end_time] = data[end_time].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "capit = pd.read_csv('data/202105-capitalbikeshare-tripdata.csv')\n",
    "capit = capit.loc[[type(i) == str for i in capit[start_station_name]]]\n",
    "capit = capit.loc[[type(i) == str for i in capit[end_station_name]]]\n",
    "# data = data.loc[data.index[:10000]]\n",
    "capit[start_time] = capit[start_time].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "capit[end_time] = capit[end_time].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "blue = pd.read_csv('data/202105-bluebikes-tripdata.csv')\n",
    "blue[start_station_name] = blue['start station name']\n",
    "blue[end_station_name] = blue['end station name']\n",
    "blue[start_lat] = blue['start station latitude']\n",
    "blue[start_lng] = blue['start station longitude']\n",
    "blue[end_lat] = blue['end station latitude']\n",
    "blue[end_lng] = blue['end station longitude']\n",
    "blue[start_time] = blue['starttime']\n",
    "blue[end_time] = blue['stoptime']\n",
    "blue = blue.loc[[type(i) == str for i in blue[start_station_name]]]\n",
    "blue = blue.loc[[type(i) == str for i in blue[end_station_name]]]\n",
    "# data = data.loc[data.index[:10000]]\n",
    "blue[start_time] = blue[start_time].apply(lambda x: datetime.strptime(x.split('.')[0], \"%Y-%m-%d %H:%M:%S\"))\n",
    "blue[end_time] = blue[end_time].apply(lambda x: datetime.strptime(x.split('.')[0], \"%Y-%m-%d %H:%M:%S\"))\n",
    "#run_test(data, name='citi')\n",
    "\n",
    "# ur = UGA_RSL()\n",
    "# print(ur.find_optimal(cwgraph))\n",
    "# u = UGA()\n",
    "# print(u.find_optimal(cwgraph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718594, 13), (219155, 13), (270893, 22))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,capit.shape,blue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding vertex data\n"
     ]
    }
   ],
   "source": [
    "interval = 120\n",
    "radius = 50\n",
    "epsilon = 20\n",
    "start_time_dt = data[start_time][np.random.choice(data.index)]\n",
    "#start_time_dt = datetime(day=5,month=5,year=2021,hour=7:30)\n",
    "td = timedelta(minutes=interval)\n",
    "cwgraph = build_cwgraph(data, start_time_dt, start_time_dt + td, radius=radius, epsilon=epsilon)\n",
    "overflow = [node for node in cwgraph.nodes() if cwgraph.nodes[node]['type'] == 'overflow']\n",
    "underflow = [node for node in cwgraph.nodes() if cwgraph.nodes[node]['type'] == 'underflow']\n",
    "worker = [node for node in cwgraph.nodes() if cwgraph.nodes[node]['type'] == 'worker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aabbtree import AABB\n",
    "from aabbtree import AABBTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wexy = [(cwgraph.nodes[node]['xs'],cwgraph.nodes[node]['ys']) for node in worker] \n",
    "wsxy = [(cwgraph.nodes[node]['xe'],cwgraph.nodes[node]['ye']) for node in worker] \n",
    "oxy = [(cwgraph.nodes[node]['x'],cwgraph.nodes[node]['y']) for node in overflow] \n",
    "uxy = [(cwgraph.nodes[node]['x'],cwgraph.nodes[node]['y']) for node in underflow] \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1 ... 88 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering,DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clustering = DBSCAN().fit_predict(oxy)\n",
    "\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-52d48360f186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_clusts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0muclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "n_clusts = int(len(graph.nodes)/5)\n",
    "print(n_clusts)\n",
    "oclustering = GaussianMixture(n_components=n_clusts).fit_predict(oxy)\n",
    "uclustering = GaussianMixture(n_components=n_clusts).fit_predict(uxy)\n",
    "clusters = pd.Series(oclustering+uclustering).unique()\n",
    "print(colors)\n",
    "colors=['#'+hex(np.random.randint(17,256))[2:]+hex(np.random.randint(17,256))[2:]+hex(np.random.randint(17,256))[2:] for i in range(max([len(clusters)]+clusters))]\n",
    "i=0\n",
    "for i in pd.Series(oclustering+uclustering).unique():\n",
    "    #print(i)\n",
    "    #print(colors[i])\n",
    "    plt.scatter([cwgraph.nodes[node]['x'] for c,node in zip(oclustering,overflow) if c==i],[cwgraph.nodes[node]['y']for  c,node in zip(oclustering,overflow) if c==i],color=colors[i],marker='+',label=i)\n",
    "    plt.scatter([cwgraph.nodes[node]['x'] for c,node in zip(uclustering,underflow) if c==i],[cwgraph.nodes[node]['y']for c,node in zip(uclustering,underflow) if c==i],color=colors[i],marker='o',label=i)\n",
    "for node in worker:\n",
    "    plt.plot([cwgraph.nodes[node]['xs'],cwgraph.nodes[node]['xe'] ],[cwgraph.nodes[node]['ys'],cwgraph.nodes[node]['ye']],label='start')\n",
    "#plt.scatter([cwgraph.nodes[node]['xe'] for node in worker],[cwgraph.nodes[node]['ye'] for node in worker],label='end')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(worker),len(overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hs import HS\n",
    "from models.trm import TRM\n",
    "graph,score = TRM().test(cwgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(np.arange(0,10,1)**4):\n",
    "    scores.append(HS().search(graph,cwgraph,threshold=i))\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,rlsscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hs import TRM_RLS\n",
    "TRM_RLS().test(cwgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greedy_density\n",
    "def get_density(node,type1,type2,cwgraph,):\n",
    "    density = 0\n",
    "    for node_ in cwgraph:    \n",
    "        if cwgraph.nodes[node_]['type'] != 'worker':\n",
    "            dis = euc_dis(cwgraph.nodes[node]['x'],cwgraph.nodes[node]['y'],cwgraph.nodes[node_]['x'],cwgraph.nodes[node_]['y'])\n",
    "            if cwgraph.nodes[node_]['type'] == type1 and dis !=0:\n",
    "                density += 1/dis \n",
    "            if cwgraph.nodes[node_]['type'] == type2 and dis!=0:\n",
    "                density -= 1/dis\n",
    "    return density\n",
    "under_densities = {node:get_density(node,'overflow','underflow',cwgraph) for node in underflow}\n",
    "over_densities = {node:get_density(node,'underflow','overflow',cwgraph) for node in overflow}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersorted = sorted(under_densities.keys(),key=lambda a:under_densities[a])\n",
    "oversorted = sorted(over_densities.keys(),key=lambda a:over_densities[a])\n",
    "available_workers = [node for node in worker]\n",
    "worker_dict = {w:[None,None] for w in worker}\n",
    "to_trim = max([len(over_densities)-max([len(overflow),len(underflow)]),0])\n",
    "\n",
    "\n",
    "\n",
    "oversorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in oversorted[to_trim:]:\n",
    "    best_worker = available_workers.pop(np.argmin([euc_dis(cwgraph.nodes[s]['x'],cwgraph.nodes[s]['y'],\n",
    "                            cwgraph.nodes[w]['xs'],cwgraph.nodes[w]['ys']) for w in available_workers]))\n",
    "    \n",
    "    worker_dict[best_worker][0] = s\n",
    "    \n",
    "available_workers = [node for node in worker]\n",
    "\n",
    "\n",
    "for s in undersorted[to_trim:]:\n",
    "    best_worker = available_workers.pop(np.argmin([euc_dis(cwgraph.nodes[s]['x'],cwgraph.nodes[s]['y'],\n",
    "                            cwgraph.nodes[w]['xe'],cwgraph.nodes[w]['ye'])for w in available_workers]))\n",
    "    \n",
    "    worker_dict[best_worker][1] = s\n",
    "worker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([euc_dis(cwgraph.nodes[w]['xs'],cwgraph.nodes[w]['xs'],cwgraph.nodes[o]['x'],cwgraph.nodes[o]['y']) + \\\n",
    "     euc_dis(cwgraph.nodes[w]['xe'],cwgraph.nodes[w]['xe'],cwgraph.nodes[u]['x'],cwgraph.nodes[u]['y']) +\\\n",
    "     euc_dis(cwgraph.nodes[o]['x'],cwgraph.nodes[o]['x'],cwgraph.nodes[u]['x'],cwgraph.nodes[u]['y']) for w,(o,u) in zip(worker_dict.keys(),worker_dict.values()) if not( u is None or o is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [[] for i in range(24)]\n",
    "print(hours)\n",
    "start_time_dt = min(metro[start_time])\n",
    "m = max(metro[start_time])\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for j in tqdm(range(90)):\n",
    "    for i in range(24):\n",
    "        oldh = hours[i]\n",
    "        hours[i].append(sum((metro[start_time] >= start_time_dt) & (metro[start_time] <= (start_time_dt+timedelta(hours=1)))))\n",
    "        start_time_dt=start_time_dt+timedelta(hours=1)\n",
    "        if hours[i] == oldh:\n",
    "            print(j)\n",
    "sum_hours = np.array([sum(hours[i]) for i in range(24)])\n",
    "sum(sum_hours)/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sum_hours)\n",
    "plt.show()\n",
    "for i in range(24):\n",
    "    plt.hist(hours[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(metro[start_time]),max(metro[start_time]),metro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metro['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 120\n",
    "radius = 50\n",
    "epsilon = 20\n",
    "start_time_m = datetime(day=5,month=5,year=2021,hour=7,minute=30)\n",
    "td = timedelta(minutes=interval)\n",
    "mdata = capit.loc[(capit[start_time]>start_time_m)&(capit[start_time]<td+start_time_m),].dropna()\n",
    "mstations = {station:{'change':0,'x':0,'y':0} for station in list(set(mdata[start_station_name].unique()).union(mdata[end_station_name].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mdata.index:\n",
    "    start_station = mdata.loc[i,start_station_name]\n",
    "    mstations[start_station]['change'] -=1 \n",
    "    x,y,_,_ = utm.from_latlon(mdata.loc[i,'start_lat'],mdata.loc[i,'start_lng'])\n",
    "    mstations[start_station]['x'] = x\n",
    "    mstations[start_station]['y'] = y\n",
    "    mstations[start_station]['lat'] = mdata.loc[i,'start_lat']\n",
    "    mstations[start_station]['lon'] = mdata.loc[i,'start_lng']\n",
    "    \n",
    "    end_station = mdata.loc[i,end_station_name]\n",
    "    mstations[end_station]['change'] +=1 \n",
    "    x,y,_,_ = utm.from_latlon(mdata.loc[i,'end_lat'],mdata.loc[i,'end_lng'])\n",
    "    mstations[end_station]['x'] = x\n",
    "    mstations[end_station]['y'] = y\n",
    "    mstations[end_station]['lat'] = mdata.loc[i,'end_lat']\n",
    "    mstations[end_station]['lon'] = mdata.loc[i,'end_lng']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[mstations[i]['x'] for i in mstations.keys()]\n",
    "y=[mstations[i]['y'] for i in mstations.keys()]\n",
    "change=[mstations[i]['change'] for i in mstations.keys()]\n",
    "delta = max([max(x)-min(x),max(y)-min(y)])+500\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.xlim(min(x)-500,min(x)+delta)\n",
    "plt.ylim(min(y)-500,min(y)+delta)\n",
    "xo = [x[i] for i in range(len(x)) if change[i] >0]\n",
    "yo = [y[i] for i in range(len(y)) if change[i] >0]\n",
    "changeo = [change[i] for i in range(len(x)) if change[i] >0]\n",
    "\n",
    "yu = [y[i] for i in range(len(y)) if change[i] <0]\n",
    "xu = [x[i] for i in range(len(x)) if change[i] <0]\n",
    "changeu = [change[i] for i in range(len(y)) if change[i] <0]\n",
    "print(len(changeu))\n",
    "\n",
    "key1 = list(mstations.keys())[0]\n",
    "key2 = list(mstations.keys())[1]\n",
    "plt.scatter(xo,yo,s=200*np.array(changeo),color='#0000ff',edgecolors='#000000',marker='s')\n",
    "plt.scatter(xu,yu,s=200*np.abs(changeu),color='#ff0000',edgecolors='#000000',marker='d')\n",
    "#plt.scatter([mstations[key1]['x']],[mstations[key1]['y']],s=200*np.abs([changeu[0]]),color='#ffff00',edgecolors='#000000')\n",
    "#plt.scatter([mstations[key2]['x']],[mstations[key2]['y']],s=200*np.abs([changeu[0]]),color='#ffff00',edgecolors='#000000')\n",
    "print(mstations[key1]['lat'] ,mstations[key1]['lon'] )\n",
    "print(mstations[key2]['lat'] ,mstations[key2]['lon'] )\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/captial_dots.png',transparent=True,format='png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)fdaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 180\n",
    "radius = 50\n",
    "epsilon = 20\n",
    "start_time_dt = data[start_time][np.random.choice(data.index)]\n",
    "start_time_dt = datetime(day=5,month=5,year=2021,hour=15,minute=0)\n",
    "td = timedelta(minutes=interval)\n",
    "e_cwgraph = build_cwgraph(data, start_time_dt, start_time_dt + td, radius=radius, epsilon=epsilon)\n",
    "e_data = pd.DataFrame([[e_cwgraph.nodes[station]['x'],e_cwgraph.nodes[station]['y'],e_cwgraph.nodes[station]['change']]for station in e_cwgraph if e_cwgraph.nodes[station]['type'] !='worker'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data.index= [station for station in e_cwgraph if e_cwgraph.nodes[station]['type'] !='worker']\n",
    "e_data.columns=['lon','lat','change']\n",
    "e_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['ff0000' if i > 0 else '0000ff' for i in m_data.change.values]\n",
    "size = e_data.change.values\n",
    "x=e_data.lon.values\n",
    "y=e_data.lat.values\n",
    "plt.scatter(x,y,c=np.sign(e_data.change.values)+1,size=size)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(metro['start_time'].values.tolist(),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[[i+j+k for i in range(2)] for j in range(4)]for k in range(3)])\n",
    "print(arr)\n",
    "arr[:::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
